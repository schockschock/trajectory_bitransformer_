{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:lightblue\">Bimodal transformer for trajectory prediction</span>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the necessary code to train the model we built to train on eth dataset. <br>\n",
    "Our approach is based on the fact that  `Attention is all you need`, not only in NLP but also in vision. <br>\n",
    "Figure 1 contains the general diagram of our model which is composed of a bimodal transformer encoder and a classical transformer decoder."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<center><img src=\"https://raw.githubusercontent.com/schockschock/trajectory_bitransformer_/main/img/trajectory_bimodal_transformer.drawio%20(2).png\" title=\"Alternative text\" width=\"1300\"/>\n",
    "<figcaption align = \"center\"> Figure 1 : Diagram of our model</figcaption>\n",
    "</center>\n",
    "</figure>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import of the librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.functional import softmax\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Normal\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "# Log\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import sqlite3\n",
    "import time\n",
    "import math\n",
    "from copy import deepcopy\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "from src.TrajectoryDataset import TrajectoryPredictionDataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"eth\" # dataset options: 'university', 'zara_01', 'zara_02', 'eth', 'hotel'\n",
    "\n",
    "#Building of output folder\n",
    "now = datetime.datetime.now() # current date and time\n",
    "__file__=os.getcwd()\n",
    "current_time_date = now.strftime(\"%d_%m_%y_%H_%M_%S\")\n",
    "run_folder  = \"Outputs/traj_pred_\"+ dataset_name + \"_\" + str(os.path.basename(__file__)) + str(current_time_date)\n",
    "os.makedirs(run_folder)\n",
    "\n",
    "# Make log folder for tensorboard\n",
    "#SummaryWriter_path = run_folder + \"/log\"\n",
    "#os.makedirs(SummaryWriter_path) \n",
    "SummaryWriter_path = '/notebook_data/work_dirs/first_test'\n",
    "writer = SummaryWriter(SummaryWriter_path,comment=\"ADE_FDE_Train\")\n",
    "\n",
    "# Make image folder to save outputs\n",
    "image_path  = run_folder + \"/Visual_Prediction\"\n",
    "os.makedirs(image_path)\n",
    "\n",
    "#cuda env\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "    torch.cuda.device_count()\n",
    "    torch.cuda.current_device()\n",
    "else :\n",
    "    device = torch.device(\"cpu\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connexion to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataBase Variables\n",
    "image_folder_path       = 'data_trajpred/'+dataset_name\n",
    "DB_PATH_train     = \"./data/Introvert_ResnetTransf/data_trajpred/\"+dataset_name+\"/pos_data_train.db\"\n",
    "cnx_train         = sqlite3.connect(DB_PATH_train)\n",
    "DB_PATH_val     = \"./data/Introvert_ResnetTransf/data_trajpred/\"+dataset_name+\"/pos_data_val.db\"\n",
    "cnx_val         = sqlite3.connect(DB_PATH_val)\n",
    "DB_DIR      = run_folder + '/database'\n",
    "os.makedirs( DB_DIR )\n",
    "DB_PATH2    = DB_DIR+'/db_one_ped_delta_coordinates_results.db'\n",
    "cnx2        = sqlite3.connect(DB_PATH2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Other variables\n",
    "T_obs                   = 8\n",
    "T_pred                  = 12\n",
    "T_total                 = T_obs + T_pred #8+12=20\n",
    "data_id                 = 0 \n",
    "batch_size              = 4 #10#100 #15 #2\n",
    "chunk_size              = batch_size * T_total # Chunksize should be multiple of T_total\n",
    "in_size                 = 2\n",
    "stochastic_out_size     = in_size * 2\n",
    "hidden_size             = 256 #!64\n",
    "embed_size              = 64 #16 #!64\n",
    "global dropout_val\n",
    "dropout_val             = 0.2 #0.5\n",
    "teacher_forcing_ratio   = 0.7 # 0.9\n",
    "regularization_factor   = 0.5 # 0.001\n",
    "avg_n_path_eval         = 20\n",
    "bst_n_path_eval         = 20\n",
    "path_mode               = \"top5\" #\"avg\",\"bst\",\"single\",\"top5\"\n",
    "regularization_mode     = \"regular\" #\"weighted\",\"e_weighted\", \"regular\"\n",
    "startpoint_mode         = \"on\" #\"on\",\"off\"\n",
    "enc_out                 = \"on\" #\"on\",\"off\"\n",
    "biased_loss_mode        = 0 # 0 , 1\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Needed methods for the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.2, 0.2)\n",
    "\n",
    "        \n",
    "def distance_from_line_regularizer(input_tensor, prediction):\n",
    "    sum_sigma_distance = torch.zeros(1)\n",
    "    input_tensor = input_tensor.double()\n",
    "    prediction = prediction.double()\n",
    "    input_tensor = input_tensor.cumsum(dim=1)\n",
    "    X = torch.ones_like(input_tensor).to('cuda', non_blocking=True)\n",
    "    X[:,:,0] = input_tensor[:,:,0]\n",
    "    Y = (input_tensor[:,:,1]).unsqueeze(-1)\n",
    "    try:\n",
    "        try:\n",
    "            XTX_1 = torch.matmul(X.transpose(-1,-2), X).inverse()\n",
    "        except:\n",
    "            XTX_1 = torch.matmul(X.transpose(-1,-2), X).ppinverse()\n",
    "        XTY = torch.matmul( X.transpose(-1,-2), Y)\n",
    "        theta = torch.matmul( XTX_1.double(), XTY)\n",
    "        \n",
    "        # Calculate real values of prediction instead of delta\n",
    "        prediction[:,:,0] = prediction[:,:,0] + input_tensor[:,-1,0].unsqueeze(-1) \n",
    "        prediction[:,:,1] = prediction[:,:,1] + input_tensor[:,-1,1].unsqueeze(-1)\n",
    "        \n",
    "        # Calculate distance ( predicted_points , observation_fitted_line ) over batch\n",
    "        theta0x0        = theta[:,0,:] * prediction[:,:,0]\n",
    "        denominator     = torch.sqrt( theta[:,0,:] * theta[:,0,:] + 1 )\n",
    "        nominator       = theta0x0 + theta[:,1,:] - prediction[:,:,1]\n",
    "        distance        = nominator.abs() / denominator\n",
    "        if regularization_mode =='weighted':\n",
    "            weight              = torch.flip( torch.arange(1,T_pred+1).cuda().double(),[0])\n",
    "            weight              = (weight / T_pred).repeat(distance.size(0)).view(-1,T_pred)\n",
    "            weighted_distance   = weight * distance\n",
    "\n",
    "        elif regularization_mode =='e_weighted':\n",
    "            weight              = torch.flip( torch.arange(1,T_pred+1).cuda().double(),[0])\n",
    "            weight              = (weight / T_pred).repeat(distance.size(0)).view(distance.size(0),T_pred)\n",
    "            weight              = torch.exp(weight)\n",
    "            weighted_distance   = weight*distance\n",
    "\n",
    "        else:\n",
    "            weighted_distance = distance\n",
    "        sigma_distance  = torch.mean(weighted_distance,1)\n",
    "        sum_sigma_distance  = torch.mean(sigma_distance)\n",
    "        return sum_sigma_distance\n",
    "    except:\n",
    "        print(\"SINGULAR VALUE\")\n",
    "        sum_sigma_distance = torch.zeros(1).to('cuda', non_blocking=True) + 20\n",
    "        return sum_sigma_distance\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
