{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:lightblue\">Bimodal transformer for trajectory prediction</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the necessary code to train the model we built to train on eth dataset. <br>\n",
    "Our approach is based on the mechanism on cross attention. <br>\n",
    "Figure 1 contains the general diagram of our model which is composed of a crossattention encoder and a classical transformer decoder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<center><img src=\"https://raw.githubusercontent.com/schockschock/trajectory_bitransformer_/main/img/Trajectory_cross_attention_transformer.drawio.png\" title=\"Alternative text\" width=\"1300\"/>\n",
    "<figcaption align = \"center\"> Figure 1 : Diagram of our model</figcaption>\n",
    "</center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import of the librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.functional import softmax\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Normal\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "# Log\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import sqlite3\n",
    "import time\n",
    "import math\n",
    "from copy import deepcopy\n",
    "import os\n",
    "import datetime\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "from models.TrajectoryDataset import TrajectoryPredictionDataset\n",
    "from models.indivSeq2SeqCA import Seq2SeqCA\n",
    "from models.resnet.feature_extraction import Resnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"eth\" # dataset options: 'university', 'zara_01', 'zara_02', 'eth', 'hotel'\n",
    "\n",
    "#Building of output folder\n",
    "now = datetime.datetime.now() # current date and time\n",
    "__file__=os.getcwd()\n",
    "current_time_date = now.strftime(\"%d_%m_%y_%H_%M_%S\")\n",
    "run_folder  = \"Outputs/traj_pred_\"+ dataset_name + \"_\" + str(os.path.basename(__file__)) + str(current_time_date)\n",
    "os.makedirs(run_folder)\n",
    "\n",
    "# Make log folder for tensorboard\n",
    "#SummaryWriter_path = run_folder + \"/log\"\n",
    "#os.makedirs(SummaryWriter_path) \n",
    "SummaryWriter_path = '/notebook_data/work_dirs/first_test'\n",
    "writer = SummaryWriter(SummaryWriter_path,comment=\"ADE_FDE_Train\")\n",
    "\n",
    "# Make image folder to save outputs\n",
    "image_path  = run_folder + \"/Visual_Prediction\"\n",
    "os.makedirs(image_path)\n",
    "\n",
    "#cuda env\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "    torch.cuda.device_count()\n",
    "    torch.cuda.current_device()\n",
    "else :\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connexion to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: 'Outputs/traj_pred_eth_trajectory_bitransformer_-main08_03_23_14_54_57/database'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m cnx_val         \u001b[38;5;241m=\u001b[39m sqlite3\u001b[38;5;241m.\u001b[39mconnect(DB_PATH_val)\n\u001b[1;32m      7\u001b[0m DB_DIR      \u001b[38;5;241m=\u001b[39m run_folder \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/database\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 8\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mDB_DIR\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m DB_PATH2    \u001b[38;5;241m=\u001b[39m DB_DIR\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/db_one_ped_delta_coordinates_results.db\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     10\u001b[0m cnx2        \u001b[38;5;241m=\u001b[39m sqlite3\u001b[38;5;241m.\u001b[39mconnect(DB_PATH2)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/os.py:225\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 225\u001b[0m     \u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# Cannot rely on checking for EEXIST, since the operating system\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# could give priority to other errors like EACCES or EROFS\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m exist_ok \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39misdir(name):\n",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: 'Outputs/traj_pred_eth_trajectory_bitransformer_-main08_03_23_14_54_57/database'"
     ]
    }
   ],
   "source": [
    "#DataBase Variables\n",
    "image_folder_path       = 'data//data_trajpred/'+dataset_name\n",
    "DB_PATH_train     = \"./data/data_trajpred/\"+dataset_name+\"/pos_data_train.db\"\n",
    "cnx_train         = sqlite3.connect(DB_PATH_train)\n",
    "DB_PATH_val     = \"./data/data_trajpred/\"+dataset_name+\"/pos_data_val.db\"\n",
    "cnx_val         = sqlite3.connect(DB_PATH_val)\n",
    "DB_DIR      = run_folder + '/database'\n",
    "os.makedirs( DB_DIR )\n",
    "DB_PATH2    = DB_DIR+'/db_one_ped_delta_coordinates_results.db'\n",
    "cnx2        = sqlite3.connect(DB_PATH2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Other variables\n",
    "T_obs                   = 8\n",
    "T_pred                  = 12\n",
    "T_total                 = T_obs + T_pred #8+12=20\n",
    "data_id                 = 0 \n",
    "batch_size              = 4 #10#100 #15 #2\n",
    "chunk_size              = batch_size * T_total # Chunksize should be multiple of T_total\n",
    "in_size                 = 2\n",
    "stochastic_out_size     = in_size * 2\n",
    "hidden_size             = 256 #!64\n",
    "embed_size              = 64 #16 #!64\n",
    "global dropout_val\n",
    "dropout_val             = 0.2 #0.5\n",
    "teacher_forcing_ratio   = 0.7 # 0.9\n",
    "regularization_factor   = 0.5 # 0.001\n",
    "avg_n_path_eval         = 20\n",
    "bst_n_path_eval         = 20\n",
    "path_mode               = \"top5\" #\"avg\",\"bst\",\"single\",\"top5\"\n",
    "regularization_mode     = \"regular\" #\"weighted\",\"e_weighted\", \"regular\"\n",
    "startpoint_mode         = \"on\" #\"on\",\"off\"\n",
    "enc_out                 = \"on\" #\"on\",\"off\"\n",
    "biased_loss_mode        = 0 # 0 , 1\n",
    "\n",
    "table_out   = \"results_delta\"\n",
    "table       = \"dataset_T_length_20delta_coordinates\" #\"dataset_T_length_\"+str(T_total)+\"delta_coordinates\"\n",
    "df_id       = pd.read_sql_query(\"SELECT data_id FROM \"+table, cnx_train)\n",
    "data_size   = df_id.data_id.max() * T_total\n",
    "epoch_num   = 100\n",
    "from_epoch  = 0\n",
    "\n",
    "#Visual Variables\n",
    "image_size              = 256  \n",
    "image_dimension         = 3\n",
    "mask_size               = 16\n",
    "visual_features_size    = 128 \n",
    "visual_embed_size       = 64  #128 #256 #64\n",
    "vsn_module_out_size    = 256\n",
    "to_pil = torchvision.transforms.ToPILImage()\n",
    "\n",
    "\n",
    "#Model Path\n",
    "model_path = run_folder + \"/NNmodel\" \n",
    "os.makedirs(model_path)   \n",
    "model_path = model_path + str(\"/model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Needed methods for the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.2, 0.2)\n",
    "\n",
    "        \n",
    "def distance_from_line_regularizer(input_tensor, prediction):\n",
    "    sum_sigma_distance = torch.zeros(1)\n",
    "    input_tensor = input_tensor.double()\n",
    "    prediction = prediction.double()\n",
    "    input_tensor = input_tensor.cumsum(dim=1)\n",
    "    X = torch.ones_like(input_tensor).to('cuda', non_blocking=True)\n",
    "    X[:,:,0] = input_tensor[:,:,0]\n",
    "    Y = (input_tensor[:,:,1]).unsqueeze(-1)\n",
    "    try:\n",
    "        try:\n",
    "            XTX_1 = torch.matmul(X.transpose(-1,-2), X).inverse()\n",
    "        except:\n",
    "            XTX_1 = torch.matmul(X.transpose(-1,-2), X).ppinverse()\n",
    "        XTY = torch.matmul( X.transpose(-1,-2), Y)\n",
    "        theta = torch.matmul( XTX_1.double(), XTY)\n",
    "        \n",
    "        # Calculate real values of prediction instead of delta\n",
    "        prediction[:,:,0] = prediction[:,:,0] + input_tensor[:,-1,0].unsqueeze(-1) \n",
    "        prediction[:,:,1] = prediction[:,:,1] + input_tensor[:,-1,1].unsqueeze(-1)\n",
    "        \n",
    "        # Calculate distance ( predicted_points , observation_fitted_line ) over batch\n",
    "        theta0x0        = theta[:,0,:] * prediction[:,:,0]\n",
    "        denominator     = torch.sqrt( theta[:,0,:] * theta[:,0,:] + 1 )\n",
    "        nominator       = theta0x0 + theta[:,1,:] - prediction[:,:,1]\n",
    "        distance        = nominator.abs() / denominator\n",
    "        if regularization_mode =='weighted':\n",
    "            weight              = torch.flip( torch.arange(1,T_pred+1).cuda().double(),[0])\n",
    "            weight              = (weight / T_pred).repeat(distance.size(0)).view(-1,T_pred)\n",
    "            weighted_distance   = weight * distance\n",
    "\n",
    "        elif regularization_mode =='e_weighted':\n",
    "            weight              = torch.flip( torch.arange(1,T_pred+1).cuda().double(),[0])\n",
    "            weight              = (weight / T_pred).repeat(distance.size(0)).view(distance.size(0),T_pred)\n",
    "            weight              = torch.exp(weight)\n",
    "            weighted_distance   = weight*distance\n",
    "\n",
    "        else:\n",
    "            weighted_distance = distance\n",
    "        sigma_distance  = torch.mean(weighted_distance,1)\n",
    "        sum_sigma_distance  = torch.mean(sigma_distance)\n",
    "        return sum_sigma_distance\n",
    "    except:\n",
    "        print(\"SINGULAR VALUE\")\n",
    "        sum_sigma_distance = torch.zeros(1).to('cuda', non_blocking=True) + 20\n",
    "        return sum_sigma_distance\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing train dataset\n",
      "Batch_size : 4\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/Introvert_ResnetTransf/data_trajpred/eth/visual_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatch_size : \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(batch_size))\n\u001b[1;32m      5\u001b[0m conv_model \u001b[38;5;241m=\u001b[39m Resnet()\n\u001b[0;32m----> 7\u001b[0m dataset_train \u001b[38;5;241m=\u001b[39m \u001b[43mTrajectoryPredictionDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_folder_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcnx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconv_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mconv_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m train_loader  \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(dataset_train, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, drop_last\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, pin_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      9\u001b[0m validation_loader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/notebook_data/trajectory_bitransformer_-main/trajectory_bitransformer_-main/models/TrajectoryDataset.py:34\u001b[0m, in \u001b[0;36mTrajectoryPredictionDataset.__init__\u001b[0;34m(self, ROOT_DIR, cnx, conv_model, load_features, return_image)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvisual_data \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# read sorted frames\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot_dir\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvisual_data\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(\n\u001b[1;32m     36\u001b[0m         Image\u001b[38;5;241m.\u001b[39mopen(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_dir)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mimg)))\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvisual_data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvisual_data)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/Introvert_ResnetTransf/data_trajpred/eth/visual_data'"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "print(\"Initializing train dataset\")\n",
    "print(\"Batch_size : {}\".format(batch_size))\n",
    "\n",
    "conv_model = Resnet()\n",
    "\n",
    "dataset_train = TrajectoryPredictionDataset(image_folder_path, cnx_train, conv_model = conv_model)\n",
    "train_loader  = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=True, num_workers=2, drop_last=True, pin_memory=True)\n",
    "validation_loader = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2SeqCA(device,embed_size=512,code_size=512,dropout_val=0.2,batch_size=batch_size)\n",
    "model = model.to(device).double()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_step               = 40\n",
    "initial_learning_rate       = 0.01\n",
    "clip                        = 1\n",
    "\n",
    "# MSE loss\n",
    "criterion                   = nn.MSELoss(reduction='mean')\n",
    "criterion_vision            = nn.MSELoss(reduction='sum')\n",
    "\n",
    "# SGD optimizer\n",
    "optimizer                   = optim.SGD(model.parameters(), lr=initial_learning_rate, momentum=0.9, weight_decay=0.01) #SGD\n",
    "scheduler                   = torch.optim.lr_scheduler.StepLR(optimizer, step_size=learning_step, gamma=0.1)\n",
    "five_fold_cross_validation  = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, save_path, filename):\n",
    "    torch.save(state, os.path.join(save_path,filename))\n",
    "    if is_best:\n",
    "        shutil.copyfile(os.path.join(save_path,filename), os.path.join(save_path,'model_best.pth'))\n",
    "        \n",
    "def train(model, optimizer, scheduler, criterion, criterion_vision, clip,train_loader, validation_loader, save_path=None):\n",
    "    global batch_size\n",
    "    i               = None\n",
    "    checked_frame   = 0\n",
    "\n",
    "    losses = []\n",
    "    print(\"Data Size \",data_size,\"\\tChunk Size \",chunk_size)\n",
    "    global teacher_forcing_ratio\n",
    "    counter =0\n",
    "    best_val = float(\"inf\")\n",
    "    for j in range(epoch_num):\n",
    "        model.train()\n",
    "        epoch_loss=0\n",
    "        if j%7 == 6:\n",
    "            teacher_forcing_ratio = (teacher_forcing_ratio - 0.2) if teacher_forcing_ratio>=0.1 else 0.0\n",
    "\n",
    "        # Update TeachForce ratio to gradually change during training\n",
    "        # global teacher_forcing_ratio\n",
    "        # teacher_forcing_ratio-= 1/epoch_num\n",
    "        print(\"TEACHER FORCE RATIO\\t\",teacher_forcing_ratio)\n",
    "        #print(\"Learning Rate\\t\", scheduler.get_last_lr())\n",
    "\n",
    "        \n",
    "        if(j>=from_epoch):\n",
    "            optimizer.zero_grad()\n",
    "            start_time = time.time()\n",
    "            ADE = 0\n",
    "            FDE = 0\n",
    "            i   = 0\n",
    "            for i,data in enumerate(train_loader):\n",
    "                #print(\"\\n--------------- Batch %d/ %d ---------------\"%(j,i)) #(epoch/i)\n",
    "                # Forward\n",
    "                obs, pred, visual_obs, frame_tensor = data\n",
    "                \n",
    "                input_tensor, output_tensor         = obs.double().squeeze(dim=1).to('cuda', non_blocking=True), pred.double().squeeze(dim=1).to('cuda', non_blocking=True)\n",
    "                    \n",
    "                visual_input_tensor                 = visual_obs.double().squeeze(dim=1).to('cuda', non_blocking=True)\n",
    "\n",
    "                prediction = model(input_tensor, output_tensor, visual_input_tensor)\n",
    "                \n",
    "                calculated_prediction = prediction.cumsum(axis=1) #calculated_prediction\n",
    "                \n",
    "                loss_line_regularizer = distance_from_line_regularizer(input_tensor,calculated_prediction) #loss (regularisation term Lreg)\n",
    "                \n",
    "                if biased_loss_mode:\n",
    "                    weight  = torch.arange(1,2*T_pred+1,2).cuda().float()\n",
    "                    weight  = torch.exp(weight / T_pred).repeat(prediction.size(0)).view(prediction.size(0),T_pred,1)\n",
    "                    loss    = criterion( (calculated_prediction)*weight, torch.cumsum(output_tensor,dim=-2)*weight)\n",
    "                else:\n",
    "                    loss    = criterion( (calculated_prediction), torch.cumsum(output_tensor,dim=-2)) #mean squared error (lmse)\n",
    "                    \n",
    "                out_x       = output_tensor[:,:,0].cumsum(axis=1)\n",
    "                out_y       = output_tensor[:,:,1].cumsum(axis=1)\n",
    "                pred_x      = calculated_prediction[:,:,0]\n",
    "                pred_y      = calculated_prediction[:,:,1]\n",
    "                ADE         += ((out_x.sub(pred_x)**2).add((out_y.sub(pred_y)**2))**(1/2)).mean(0).mean(0)   \n",
    "                # FDE      += ((out_x.sub(pred_x)**2).add((out_y.sub(pred_y)**2))**(1/2)).mean(0)[-1]\n",
    "                \n",
    "                # Backward Propagation\n",
    "                total_loss      = loss.double() + torch.tensor(regularization_factor).to('cuda', non_blocking=True) * loss_line_regularizer.double() #total loss\n",
    "                total_loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "                optimizer.step()\n",
    "                #print(\"Total Loss\\t{:.2f}\".format(total_loss.item()))\n",
    "                epoch_loss += total_loss.item()\n",
    "                #print(\"Time\\t\\t{:.2f} sec \\n\".format(time.time() - start_time))\n",
    "                start_time = time.time()\n",
    "                torch.cuda.empty_cache()\n",
    "                writer.close()\n",
    "                count_div=i\n",
    "            \n",
    "            # tensorboard log\n",
    "            writer.add_scalar('ADE/train', ADE.item()/(count_div+1), counter)\n",
    "            # writer.add_scalar('FDE/train', FDE.item()/(count_div+1), counter)\n",
    "            # writer.add_scalar('LOSS/train', epoch_loss/(count_div+1), counter)\n",
    "            counter += 1\n",
    "\n",
    "        if scheduler.get_last_lr()[0]>0.001:\n",
    "            scheduler.step()\n",
    "        # validation(model, optimizer, criterion, criterion_vision, clip, validation_loader, j) \n",
    "        epoch_loss = epoch_loss / (int(data_size/chunk_size))\n",
    "        losses.append(epoch_loss)\n",
    "        display.clear_output(wait=True)\n",
    "        plt.plot(losses, '--ro', label='train loss')\n",
    "        plt.legend()\n",
    "        plt.title(f'epoch {j}')\n",
    "        plt.show()\n",
    "        print(\"Time\\t\\t{:.2f} sec \\n\".format(time.time() - start_time))\n",
    "        print(\"EPOCH \", j, \"\\tLOSS \", epoch_loss)\n",
    "        writer.add_scalar('epoch_loss/train', epoch_loss/ (int(data_size/chunk_size)), j ) #see how model performs on the training dataset\n",
    "        #torch.save( model.state_dict(), model_path+\"_current\")\n",
    "        print(\"-----------------------------------------------\\n\"+\"-----------------------------------------------\")\n",
    "\n",
    "        # save checkpoint for each epoch and a fine called best_model so far \n",
    "        print(np.argmin(losses))\n",
    "        is_best = epoch_loss < best_val\n",
    "        best_val = min(epoch_loss, best_val)\n",
    "        print(\"bestvaleur\", best_val)\n",
    "        if save_path and (j+1)%5==0:\n",
    "            save_checkpoint({'epoch': j+1,'state_dict': model.state_dict(),'optimizer': optimizer.state_dict(),'scheduler': scheduler.state_dict(),'best_loss': best_val}, is_best, save_path, 'epoch_{}.pth'.format(j+1))\n",
    "        \n",
    "    return epoch_loss / (int(data_size/chunk_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "path mode\t top5\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\33789\\Documents\\imt\\p5_transformer\\trajectory_bitransformer_\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msave_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"/notebook_data/Introvert_ResnetTransf/save_models/cross_attention/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mloss\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion_vision\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"LOSS \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"TRAIN\")\n",
    "model.train()\n",
    "print(\"path mode\\t\",path_mode)\n",
    "\n",
    "save_path = \"/notebook_data/Introvert_ResnetTransf/save_models/cross_attention/\"\n",
    "loss  = train(model, optimizer, scheduler, criterion, criterion_vision, clip, train_loader, validation_loader, save_path)\n",
    "print(\"LOSS \",loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, optimizer, criterion, criterion_vision, clip, validation_loader, counter):\n",
    "    global batch_size\n",
    "    model.eval()\n",
    "    i           = None\n",
    "    ADEs        = 0\n",
    "    FDEs        = 0\n",
    "    epoch_loss  = 0\n",
    "    loss_line_regularizer = 0\n",
    "    loss = 0 \n",
    "    total_loss = 0\n",
    "    ADE  = 0\n",
    "    FDE  = 0\n",
    "    for i,data in enumerate(test_loader):\n",
    "        # Forward\n",
    "        obs, pred, visual_obs, frame_tensor = data\n",
    "\n",
    "        input_tensor, output_tensor         = obs.double().squeeze(dim=1).to('cuda', non_blocking=True), pred.double().squeeze(dim=1).to('cuda', non_blocking=True)\n",
    "\n",
    "        visual_input_tensor                 = visual_obs.double().squeeze(dim=1).to('cuda', non_blocking=True)\n",
    "\n",
    "        prediction = model(input_tensor, output_tensor, visual_input_tensor) \n",
    "        \n",
    "        calculated_prediction = prediction.cumsum(axis=1) \n",
    "\n",
    "        loss_line_regularizer = distance_from_line_regularizer(input_tensor,calculated_prediction)\n",
    "        \n",
    "        if biased_loss_mode:\n",
    "            weight  = torch.arange(1,2*T_pred+1,2).cuda().float()\n",
    "            weight  = torch.exp(weight / T_pred).repeat(prediction.size(0)).view(prediction.size(0),T_pred,1)\n",
    "            loss    = criterion( (calculated_prediction)*weight, torch.cumsum(output_tensor,dim=-2)*weight)\n",
    "        else:\n",
    "            loss    = criterion( (calculated_prediction), torch.cumsum(output_tensor,dim=-2))\n",
    "            \n",
    "        out_x       = output_tensor[:,:,0].cumsum(axis=1)\n",
    "        out_y       = output_tensor[:,:,1].cumsum(axis=1)\n",
    "        pred_x      = calculated_prediction[:,:,0]\n",
    "        pred_y      = calculated_prediction[:,:,1]\n",
    "        ADE         += ((out_x.sub(pred_x)**2).add((out_y.sub(pred_y)**2))**(1/2)).mean(0).mean(0)   \n",
    "        FDE         += ((out_x.sub(pred_x)**2).add((out_y.sub(pred_y)**2))**(1/2)).mean(0)[-1]\n",
    "        total_loss  += loss.double() + regularization_factor * loss_line_regularizer.double() \n",
    "        print(\"Total Loss\\t{:.2f}\".format(total_loss.item()))\n",
    "\n",
    "    writer.add_scalar('ADE/val_'+path_mode,             ADE.item()/(i+1),             counter)\n",
    "    writer.add_scalar('FDE/val_'+path_mode,             FDE.item()/(i+1),             counter)\n",
    "    writer.add_scalar('LOSS/val_'+path_mode,            total_loss.item()/(i+1)   ,   counter)\n",
    "    writer.add_scalar('LOSS_c/val_'+path_mode,          loss.item()/(i+1)        ,    counter)\n",
    "    writer.add_scalar('L-REGULARIZER/val_'+path_mode,   loss_line_regularizer.item()/(i+1), counter)\n",
    "    writer.close()\n",
    "    \n",
    "def evaluate_eval(model, criterion):\n",
    "    global batch_size\n",
    "    model.eval()\n",
    "    i           = None\n",
    "    ADEs        = 0\n",
    "    FDEs        = 0\n",
    "    epoch_loss  = 0\n",
    "    list_x_obs          = ['x_obs_'+str(i)              for i in range(0,T_obs)] #x_obs_0 --> x_obs_7\n",
    "    list_y_obs          = ['y_obs_'+str(i)              for i in range(0,T_obs)] #y_obs_0 --> y_obs_7\n",
    "    list_c_context      = ['context_c_'+str(i)          for i in range(0,hidden_size)] #context_c_0 --> context_c_255\n",
    "    list_h_context      = ['context_h_'+str(i)          for i in range(0,hidden_size)] #context_h_0 --> context_h_255\n",
    "    list_x_pred         = ['x_pred_'+str(i)             for i in range(0,T_pred)] #x_pred_0 --> x_pred_11\n",
    "    list_y_pred         = ['y_pred_'+str(i)             for i in range(0,T_pred)] #y_pred_0 --> y_pred_11\n",
    "    list_x_stoch_pred_m = ['x_stoch_pred_m_'+str(i)     for i in range(0,T_pred)] #x_stoch_pred_m_0 --> x_stoch_pred_m_11\n",
    "    list_y_stoch_pred_m = ['y_stoch_pred_m_'+str(i)     for i in range(0,T_pred)] #y_stoch_pred_m_0 --> y_stoch_pred_m_11\n",
    "    list_x_stoch_pred_s = ['x_stoch_pred_s_'+str(i)     for i in range(0,T_pred)] #x_stoch_pred_s_0 --> x_stoch_pred_s_11\n",
    "    list_y_stoch_pred_s = ['y_stoch_pred_s_'+str(i)     for i in range(0,T_pred)] #y_stoch_pred_s_0 --> y_stoch_pred_s_11\n",
    "    list_x_out          = ['x_out_'+str(i)              for i in range(0,T_pred)] #x_out_0 --> x_out_11\n",
    "    list_y_out          = ['y_out_'+str(i)              for i in range(0,T_pred)] #y_out_0 --> y_out_11\n",
    "    list_vsn            = ['vsn_'+str(i)               for i in range(0,hidden_size)] #vsn_0 --> vsn_255\n",
    "    df_out              = pd.DataFrame(columns=list_x_obs + list_y_obs + list_x_out + list_y_out + list_x_pred + list_y_pred + list_x_stoch_pred_m + list_y_stoch_pred_m + list_x_stoch_pred_s + list_y_stoch_pred_s + list_c_context + list_h_context + list_vsn)# + list_vsn_visual)\n",
    "\n",
    "    for i,data in enumerate(test_loader):\n",
    "        start_time = time.time()\n",
    "        # Forward\n",
    "        obs, pred, visual_obs, frame_tensor = data\n",
    "\n",
    "        input_tensor, output_tensor         = obs.double().squeeze(dim=1).to('cuda', non_blocking=True), pred.double().squeeze(dim=1).to('cuda', non_blocking=True)\n",
    "\n",
    "        visual_input_tensor                 = visual_obs.double().squeeze(dim=1).to('cuda', non_blocking=True)\n",
    "\n",
    "        prediction = model(input_tensor, output_tensor, visual_input_tensor) \n",
    "    \n",
    "        calculated_prediction =  prediction.cumsum(axis=1) \n",
    "\n",
    "        loss_line_regularizer = distance_from_line_regularizer(input_tensor,calculated_prediction) #lreg\n",
    "\n",
    "        if biased_loss_mode:\n",
    "            weight  = torch.arange(1,2*T_pred+1,2).cuda().float()\n",
    "            weight  = torch.exp(weight / T_pred).repeat(prediction.size(0)).view(prediction.size(0),T_pred,1)\n",
    "            loss    = criterion( (calculated_prediction)*weight, torch.cumsum(output_tensor,dim=-2)*weight)\n",
    "        else:\n",
    "            loss    = criterion( (calculated_prediction), torch.cumsum(output_tensor,dim=-2)) #lmse\n",
    "        out_x           = output_tensor[:,:,0].cumsum(axis=1)\n",
    "        out_y           = output_tensor[:,:,1].cumsum(axis=1)\n",
    "        pred_x          = calculated_prediction[:,:,0]\n",
    "        pred_y          = calculated_prediction[:,:,1]\n",
    "        ADE             = ((out_x.sub(pred_x)**2).add((out_y.sub(pred_y)**2))**(1/2)).mean(0).mean(0)   \n",
    "        FDE             = ((out_x.sub(pred_x)**2).add((out_y.sub(pred_y)**2))**(1/2)).mean(0)[-1]\n",
    "        total_loss      = loss.double() + regularization_factor * loss_line_regularizer.double() #loss\n",
    "        print(\"Total Loss\\t{:.2f}\".format(total_loss.item()))\n",
    "        epoch_loss += total_loss.item()\n",
    "        ADEs    += ADE.item()\n",
    "        FDEs    += FDE.item()\n",
    "        input_x_lin                 = input_tensor[:,:,0].view(-1, T_obs).cpu() #x_obs\n",
    "        input_y_lin                 = input_tensor[:,:,1].view(-1, T_obs).cpu() #y_obs\n",
    "        output_x_lin                = output_tensor[:,:,0].view(-1, T_pred).cpu() #x_out\n",
    "        output_y_lin                = output_tensor[:,:,1].view(-1, T_pred).cpu() #y_out\n",
    "        prediction_x_lin            = prediction[:,:,0].view(-1, T_pred).cpu() #x_pred\n",
    "        prediction_y_lin            = prediction[:,:,1].view(-1, T_pred).cpu() #y_pred\n",
    "\n",
    "\n",
    "        print(\"Time\\t\\t{:.2f} sec \\n\".format(time.time() - start_time))\n",
    "\n",
    "    # ADE/FDE Report\n",
    "    out_x  = df_out[['x_out_' +str(i) for i in range(0,T_pred)]].cumsum(axis=1)\n",
    "    pred_x = df_out[['x_pred_'+str(i) for i in range(0,T_pred)]].cumsum(axis=1)\n",
    "    out_y  = df_out[['y_out_' +str(i) for i in range(0,T_pred)]].cumsum(axis=1)\n",
    "    pred_y = df_out[['y_pred_'+str(i) for i in range(0,T_pred)]].cumsum(axis=1)\n",
    "    ADE = (out_x.sub(pred_x.values)**2).add((out_y.sub(pred_y.values)**2).values, axis=1)**(1/2)\n",
    "    df_out['ADE'] = ADE.mean(axis=1)\n",
    "    FDE = ADE.x_out_11\n",
    "    df_out['FDE'] = FDE\n",
    "    Mean_ADE = df_out.ADE.mean()\n",
    "    Mean_FDE = df_out.FDE.mean()\n",
    "    print(\"MEAN ADE/FDE\\t\",Mean_ADE,Mean_FDE)\n",
    "    writer.add_scalar(\"Final_Test/ADE_\"+path_mode, Mean_ADE, global_step=0)\n",
    "    writer.add_scalar(\"Final_Test/FDE_\"+path_mode, Mean_FDE, global_step=0)\n",
    "\n",
    "    df_out.to_sql(table_out+'_'+path_mode, cnx2, if_exists=\"replace\", index=False)\n",
    "    writer.close()\n",
    "    return ADEs, FDEs, int(data_size/chunk_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method to load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(model, optimizer, scheduler, filename='checkpoint.pth.tar'):\n",
    "    start_epoch = 0\n",
    "    best_val=-1\n",
    "    if os.path.isfile(filename):\n",
    "        print(\"=> loading checkpoint '{}'\".format(filename))\n",
    "        checkpoint = torch.load(filename)\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        scheduler.load_state_dict(checkpoint['scheduler'])\n",
    "        try:\n",
    "            best_val=checkpoint['best_loss']\n",
    "        except:\n",
    "            best_val=-1\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\".format(filename, checkpoint['epoch']))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(filename))\n",
    "\n",
    "    return model, optimizer, scheduler, start_epoch, best_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading of model\n",
    "model_dir = \"/notebook_data/Introvert_ResnetTransf/save_models/cross_attention/model_best.pth\"\n",
    "print(\"LOAD MODEL\")\n",
    "# Change device to cpu\n",
    "#del model\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "model = Seq2SeqCA(device,embed_size=512,code_size=512,dropout_val=dropout_val,batch_size=batch_size)\n",
    "model = model.to(device).double()\n",
    "model, optimizer, scheduler, start_epoch, best_val = load_checkpoint(model, optimizer, scheduler, filename= model_dir)\n",
    "\n",
    "#test dataset and loader\n",
    "print(\"Initializing val dataset\")\n",
    "dataset_val   = TrajectoryPredictionDataset(image_folder_path, cnx_val)\n",
    "test_loader   = torch.utils.data.DataLoader(dataset_val, batch_size=batch_size, shuffle=False, num_workers=2, drop_last=False, pin_memory=True)\n",
    "\n",
    "#Evaluation\n",
    "print(\"EVALUATE bst\")\n",
    "model.eval()\n",
    "path_mode = 'bst'\n",
    "print(\"path mode\\t\",path_mode)\n",
    "evaluate_eval(model, criterion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
